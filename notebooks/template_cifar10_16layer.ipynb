{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQeBbCYZlhKn",
        "outputId": "37e7e041-8328-4c43-e027-c20560d21227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 17.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 15.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 15.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 512 kB 15.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 72.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUnIVvd-lxxZ",
        "outputId": "78b77ab9-8df4-42b8-a347-64f1e8ac55a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 121 kB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 73.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for GraphVision (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install our repo\n",
        "# !git clone -b models \"https://github.com/ab7289-tandon-nyu/GraphVision.git\"\n",
        "# !cp -r /content/GraphVision/src/ .\n",
        "\n",
        "!pip install -q git+https://github.com/ab7289-tandon-nyu/GraphVision.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4hY3Lomuoya8"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxCBs1jTriNW",
        "outputId": "5338a541-db19-4a1c-f6bd-0d133c9d570b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wuj1_P_3m0-l",
        "outputId": "30494dd7-31b4-40a5-8ab1-ca7df34a26a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/benchmarking-gnns/CIFAR10_v2.zip\n",
            "Extracting .data/CIFAR10/raw/CIFAR10_v2.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from src.transforms import get_transforms\n",
        "from src.datasets import get_datasets, get_dataloaders\n",
        "\n",
        "transforms = get_transforms(\"cartesian\")\n",
        "train_dataset, valid_dataset, test_dataset = get_datasets(\".data/\", \n",
        "                        \"CIFAR10\", pre_transforms = None,\n",
        "                        transforms = transforms)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_dataloaders(train_dataset,\n",
        "                                                          valid_dataset,\n",
        "                                                          test_dataset,\n",
        "                                                          batch_size=(BATCH_SIZE, 1, 1),\n",
        "                                                          drop_last = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjmgy7RvoJN-"
      },
      "source": [
        "## Review batch attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QCa0O4IoM6U",
        "outputId": "ee3a50a1-41ab-414b-baa0-08cbfa434a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataBatch(x=[14981, 3], edge_index=[2, 134829], edge_attr=[134829, 2], y=[128], pos=[14981, 2], edge_weight=[134829], batch=[14981], ptr=[129])\n",
            "=====================================================================\n",
            "Number of features:  3\n",
            "Number of node features: 3\n",
            "Number of nodes: 14981\n",
            "Number of edges: 134829\n",
            "Average node degree: 9.00\n",
            "Has isolated nodes: False\n",
            "Has self-loops: True\n"
          ]
        }
      ],
      "source": [
        "sample_batch = next(iter(train_loader))\n",
        "\n",
        "print()\n",
        "print(sample_batch)\n",
        "print(\"=====================================================================\")\n",
        "\n",
        "# Gather some statistics about the first graph.\n",
        "print(f\"Number of features:  {sample_batch.num_features}\")\n",
        "print(f\"Number of node features: {sample_batch.num_node_features}\")\n",
        "print(f'Number of nodes: {sample_batch.num_nodes}')\n",
        "print(f'Number of edges: {sample_batch.num_edges}')\n",
        "print(f'Average node degree: {sample_batch.num_edges / sample_batch.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {sample_batch.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {sample_batch.has_self_loops()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu3VtmrWpnZx",
        "outputId": "6da88426-d092-4977-9612-42c7cafaff20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 3\n",
            "Number of classes: 10\n",
            "Edge Attr Dimension: 2\n"
          ]
        }
      ],
      "source": [
        "# store edge dimension\n",
        "edge_dim = sample_batch.edge_attr.size(-1)\n",
        "edge_dim\n",
        "# store number of features in graph batch\n",
        "input_features = test_dataset.num_features\n",
        "# store number of classes for classification\n",
        "num_classes = test_dataset.num_classes\n",
        "\n",
        "print(f\"Number of features: {input_features}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Edge Attr Dimension: {edge_dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqiZaFw2ps9r",
        "outputId": "e541e406-d71e-47c5-c128-a247fbab4cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Save!\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "save_loc = \"/content/drive/MyDrive/saved_models/\" # put save location here\n",
        "model_name = \"GENConv_clus-false_BN_RELU_layer16_h128.pt\"\n",
        "\n",
        "file_path = save_loc + model_name\n",
        "path = Path(file_path)\n",
        "state_dict = None\n",
        "if path.exists() and path.is_file():\n",
        "  print(\"Found Save!\")\n",
        "  state_dict = torch.load(path)\n",
        "else:\n",
        "  print(\"Creating new Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGiE28k32eUr"
      },
      "source": [
        "## Create our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "epF5kpJcqWJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13655a88-c92f-43ba-edff-56292e12fa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading previously saved state dictionary\n"
          ]
        }
      ],
      "source": [
        "from src.models import DeeperGCN\n",
        "from src.engine import evaluate\n",
        "\n",
        "hidden_features = 128\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DeeperGCN(\n",
        "    input_features,\n",
        "    num_classes,\n",
        "    hidden_features,\n",
        "    conv_type = \"GEN\",\n",
        "    act = \"relu\",\n",
        "    norm = \"batch\",\n",
        "    num_layers = 16,\n",
        "    use_cluster_pooling = False,\n",
        "    readout = \"mean\",\n",
        "    dropout = 0.25,\n",
        "    edge_dim = edge_dim\n",
        ").to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "prev_loss = None\n",
        "if state_dict is not None:\n",
        "  print(\"Loading previously saved state dictionary\")\n",
        "  model.load_state_dict(state_dict)\n",
        "  prev_loss, _ = evaluate(model.to(device), test_loader, criterion, device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsm1MwvSr0nU",
        "outputId": "812e3825-4812-4d7d-d0ae-ddea1d7d1c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1,066,778 trainable parameters.\n",
            "\n",
            "DeeperGCN(\n",
            "  (fc_in): Linear(in_features=3, out_features=128, bias=True)\n",
            "  (fc_out): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (out_act): ReLU(inplace=True)\n",
            "  (layers): ModuleList(\n",
            "    (0): DeepGCNLayer(block=res+)\n",
            "    (1): DeepGCNLayer(block=res+)\n",
            "    (2): DeepGCNLayer(block=res+)\n",
            "    (3): DeepGCNLayer(block=res+)\n",
            "    (4): DeepGCNLayer(block=res+)\n",
            "    (5): DeepGCNLayer(block=res+)\n",
            "    (6): DeepGCNLayer(block=res+)\n",
            "    (7): DeepGCNLayer(block=res+)\n",
            "    (8): DeepGCNLayer(block=res+)\n",
            "    (9): DeepGCNLayer(block=res+)\n",
            "    (10): DeepGCNLayer(block=res+)\n",
            "    (11): DeepGCNLayer(block=res+)\n",
            "    (12): DeepGCNLayer(block=res+)\n",
            "    (13): DeepGCNLayer(block=res+)\n",
            "    (14): DeepGCNLayer(block=res+)\n",
            "    (15): DeepGCNLayer(block=res+)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "print(f\"There are {params:,} trainable parameters.\")\n",
        "print()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuoamYXu2hf-"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pyJ2olIr9pi",
        "outputId": "1e4c44c0-e06f-4388-ac50-5b5c19f9c9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training from previous best loss: 1.656497934228368\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "Train Loss: 1.392, Train Accuracy: 0.49\n",
            "Validation Loss: 1.845, Validation Accuracy: 0.33\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Train Loss: 1.372, Train Accuracy: 0.50\n",
            "Validation Loss: 1.975, Validation Accuracy: 0.35\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Train Loss: 1.368, Train Accuracy: 0.50\n",
            "Validation Loss: 1.804, Validation Accuracy: 0.37\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Train Loss: 1.353, Train Accuracy: 0.51\n",
            "Validation Loss: 1.878, Validation Accuracy: 0.36\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Train Loss: 1.343, Train Accuracy: 0.51\n",
            "Validation Loss: 1.910, Validation Accuracy: 0.36\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Train Loss: 1.334, Train Accuracy: 0.52\n",
            "Validation Loss: 1.681, Validation Accuracy: 0.41\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Train Loss: 1.326, Train Accuracy: 0.52\n",
            "Validation Loss: 1.560, Validation Accuracy: 0.43\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "Train Loss: 1.312, Train Accuracy: 0.52\n",
            "Validation Loss: 1.760, Validation Accuracy: 0.37\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Train Loss: 1.306, Train Accuracy: 0.53\n",
            "Validation Loss: 2.164, Validation Accuracy: 0.33\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Train Loss: 1.305, Train Accuracy: 0.53\n",
            "Validation Loss: 1.805, Validation Accuracy: 0.39\n",
            "\n",
            "Epoch: 11\n",
            "\n",
            "Train Loss: 1.293, Train Accuracy: 0.53\n",
            "Validation Loss: 1.624, Validation Accuracy: 0.40\n",
            "\n",
            "Epoch: 12\n",
            "\n",
            "Train Loss: 1.286, Train Accuracy: 0.54\n",
            "Validation Loss: 1.612, Validation Accuracy: 0.43\n",
            "\n",
            "Epoch: 13\n",
            "\n",
            "Train Loss: 1.280, Train Accuracy: 0.54\n",
            "Validation Loss: 1.769, Validation Accuracy: 0.40\n",
            "\n",
            "Epoch: 14\n",
            "\n",
            "Train Loss: 1.275, Train Accuracy: 0.54\n",
            "Validation Loss: 1.726, Validation Accuracy: 0.40\n",
            "\n",
            "Epoch: 15\n",
            "\n",
            "Train Loss: 1.272, Train Accuracy: 0.54\n",
            "Validation Loss: 1.693, Validation Accuracy: 0.43\n",
            "\n",
            "Epoch: 16\n",
            "\n",
            "Train Loss: 1.266, Train Accuracy: 0.54\n",
            "Validation Loss: 1.679, Validation Accuracy: 0.42\n",
            "\n",
            "Epoch: 17\n",
            "\n",
            "Train Loss: 1.253, Train Accuracy: 0.55\n",
            "Validation Loss: 1.455, Validation Accuracy: 0.47\n",
            "\n",
            "Epoch: 18\n",
            "\n",
            "Train Loss: 1.250, Train Accuracy: 0.55\n",
            "Validation Loss: 1.588, Validation Accuracy: 0.43\n",
            "\n",
            "Epoch: 19\n",
            "\n",
            "Train Loss: 1.242, Train Accuracy: 0.55\n",
            "Validation Loss: 1.824, Validation Accuracy: 0.39\n",
            "\n",
            "Epoch: 20\n",
            "\n",
            "Train Loss: 1.236, Train Accuracy: 0.56\n",
            "Validation Loss: 1.620, Validation Accuracy: 0.43\n",
            "\n",
            "Epoch: 21\n",
            "\n",
            "Train Loss: 1.232, Train Accuracy: 0.55\n",
            "Validation Loss: 1.815, Validation Accuracy: 0.41\n",
            "\n",
            "Epoch: 22\n",
            "\n",
            "Train Loss: 1.230, Train Accuracy: 0.55\n",
            "Validation Loss: 1.780, Validation Accuracy: 0.40\n",
            "\n",
            "Epoch: 23\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from src.engine import train\n",
        "from src.utils import calculate_accuracy\n",
        "\n",
        "EPOCHS = 78\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "best_loss = float('inf')\n",
        "if prev_loss is not None:\n",
        "  print(f\"Training from previous best loss: {prev_loss}\")\n",
        "  best_loss = prev_loss\n",
        "  \n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  print(f\"\\nEpoch: {epoch}\\n\")\n",
        "  loss, acc = train(model, train_loader, criterion, optimizer, device)\n",
        "  train_loss.append(loss)\n",
        "  train_acc.append(acc)\n",
        "  print(f\"Train Loss: {train_loss[-1]:.3f}, Train Accuracy: {train_acc[-1]:.2f}\")\n",
        "\n",
        "  loss, acc = evaluate(model, valid_loader, criterion, device)\n",
        "  valid_loss.append(loss)\n",
        "  valid_acc.append(acc)\n",
        "  print(f\"Validation Loss: {valid_loss[-1]:.3f}, Validation Accuracy: {valid_acc[-1]:.2f}\")\n",
        "\n",
        "  if loss < best_loss:\n",
        "    best_loss = loss\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIu5vZ3d2jNJ"
      },
      "source": [
        "## Evaluate on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5oWJj8g11MF"
      },
      "outputs": [],
      "source": [
        "# load best model\n",
        "model.load_state_dict(torch.load(path))\n",
        "test_loss, test_acc = evaluate(model.to(device), test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.3f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvOfsB752las"
      },
      "source": [
        "## Plot Loss and Accuracy Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk6I1WkDvWmE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [i for i in range(len(valid_loss))]\n",
        "\n",
        "plt.plot(x, train_loss, label=\"Train Loss\")\n",
        "plt.plot(x, valid_loss, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-xP3uX63aT8"
      },
      "outputs": [],
      "source": [
        "plt.plot(x, train_acc, label=\"Train Accuracy\")\n",
        "plt.plot(x, valid_acc, label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_FdIR923n9N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pyg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "602fd2f1343589d3bd6f27fae416162c1bba08e244faa27258d2511dac84d913"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}